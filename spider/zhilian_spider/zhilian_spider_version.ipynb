{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import requests\n",
    "import json\n",
    "import pymysql\n",
    "import re\n",
    "import gevent\n",
    "import multiprocessing as mul\n",
    "from gevent.pool import Pool\n",
    "from multiprocessing import Manager, Process\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "\n",
    "def get_content(url, content_list):\n",
    "    print('start spider:', url)\n",
    "    content = requests.get(url).content.decode()\n",
    "    print(len(content))\n",
    "    if len(content) < 500:\n",
    "        raise IndexError\n",
    "    content_dict = json.loads(content)\n",
    "    data_dict = content_dict['data']['results']\n",
    "    content_list.append(data_dict)\n",
    "\n",
    "\n",
    "def get_use_msg(content, result_list):\n",
    "    for data in content:\n",
    "        job = data['jobName']\n",
    "        city = data['city']['items'][0]['name']\n",
    "        work_exp = data['workingExp']['name']\n",
    "        edu = data['eduLevel']['name']\n",
    "        salary = data['salary']\n",
    "        company = data['company']['name']\n",
    "        empl_type = data['emplType']\n",
    "        msg_dict = {\n",
    "            'job': job,\n",
    "            'city': city,\n",
    "            'work_exp': work_exp,\n",
    "            'edu': edu,\n",
    "            'salary': salary,\n",
    "            'company': company,\n",
    "            'empl_type': empl_type,\n",
    "        }\n",
    "        result_list.append(msg_dict)\n",
    "\n",
    "\n",
    "def thread_run_get_msg(content_list, result_list):\n",
    "    for content in content_list:\n",
    "        get_use_msg(content, result_list)\n",
    "\n",
    "\n",
    "def save_to_sql(dic):\n",
    "    conn = pymysql.connect(\n",
    "        host='localhost',\n",
    "        user='root',\n",
    "        password='xzx199110',\n",
    "        database='bs',\n",
    "        port=3306,\n",
    "    )\n",
    "    cursor = conn.cursor()\n",
    "    print('start save ', dic['job'])\n",
    "    sql = \"\"\"\n",
    "    insert into zhilian_test (job, city, work_exp, edu, salary, company,\n",
    "     empl_type) values (%s, %s, %s, %s, %s, %s, %s)\"\"\"\n",
    "    try:\n",
    "        cursor.execute(sql, (dic['job'], dic['city'], dic['work_exp'],\n",
    "                             dic['edu'], dic['salary'], dic['company'], dic['empl_type']))\n",
    "        conn.commit()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "\n",
    "def gen_one_list(url: str, salary: tuple, kw: str, url_list):\n",
    "    url = re.sub('&kw=(.*?)&', '&kw=' + kw + '&', url, count=0, flags=0)\n",
    "    url = re.sub('&salary=[\\d]+,(.*?)&', '&salary=' + str(salary[0]) + ',' + str(salary[1]) + '&', url)\n",
    "    print('gen', url)\n",
    "    url_list.append(url)\n",
    "\n",
    "\n",
    "def gen_kw_url_list(base_url, salary_list, kw_list, url_list):\n",
    "    for kw in kw_list:\n",
    "        for salary in salary_list:\n",
    "            print('gen ', kw, salary)\n",
    "            gen_one_list(base_url, salary, kw, url_list)\n",
    "\n",
    "\n",
    "def thread_run_get_content(url_list, content_list):\n",
    "    start = 0\n",
    "    for url in url_list:\n",
    "        while True:\n",
    "            url = re.sub('\\?start=(\\d+)', '?start=' + str(start), url, count=0, flags=0)\n",
    "            start += 90\n",
    "            try:\n",
    "                get_content(url, content_list)\n",
    "            except BaseException:\n",
    "                print(url, 'wrong')\n",
    "                break\n",
    "    print('test')\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    url = '''https://fe-api.zhaopin.com/c/i/sou?start=90&pageSize=90&cityId=489&salary=1,1000&workExperience=-1&education=-1&companyType=-1&employmentType=-1&jobWelfareTag=-1&kw=python&kt=3&=1&_v=0.54277500&x-zp-page-request-id=20aa3cf26b9d4d05b4aaafe175de0c6d-1552385870753-809381'''\n",
    "    salary_list = [(1, 1000), (1001, 2000), (2001, 4000), (4001, 6000),\n",
    "                   (6001, 8000), (8001, 10000), (10001, 15000), (15001, 25000),\n",
    "                   (25001, 35000), (35001, 50000), (50001, 70000), (70001, 100000),\n",
    "                   (100001, 999999)]\n",
    "    kw_list = ['python', 'java', 'c', 'c++']\n",
    "    result_list = Manager().list()\n",
    "    content_list = Manager().list()\n",
    "    url_list = Manager().list()\n",
    "\n",
    "    print('start get gen url')\n",
    "    p1 = Process(target=gen_kw_url_list, args=(url, salary_list, kw_list, url_list))\n",
    "    p2 = Process(target=thread_run_get_content, args=(url_list, content_list))\n",
    "    p3 = Process(target=thread_run_get_msg, args=(content_list, result_list))\n",
    "\n",
    "    p1.start()\n",
    "    p2.start()\n",
    "    p3.start()\n",
    "\n",
    "    p1.join()\n",
    "    p2.join()\n",
    "    p3.join()\n",
    "\n",
    "    pool = Pool(size=10, greenlet_class=None)\n",
    "\n",
    "    print('start save')\n",
    "    pool.map(save_to_sql, result_list)\n",
    "    print('save over')\n"
   ]
  }
 ],
 "metadata": {
  "language": "python"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
